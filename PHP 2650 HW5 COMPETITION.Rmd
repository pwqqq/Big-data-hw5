---
title: "php 2650 hw5"
date: "4/22/2018"
output: html_document
---

```{r}
library(data.table)
require(Matrix)
require(data.table)
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
require(xgboost)
library(klaR)

```


```{r}
# read in test data
#test <- fread("Predict_NoShow_PrivateTest_WithoutLabels.csv", header = TRUE)
#test2 <- fread("Predict_NoShow_PublicTest_WithoutLabels.csv", header = TRUE)

# read in train data
train_total <- fread("Predict_NoShow_Train.csv", header = TRUE)
train_total <- train_total[,-4] # delete first date column
train_total <- train_total[,-4] # delete second date column
id <- train_total[,1] # delete ID column
train_total <- train_total[,-1] # save ID column for further use 

# train data 2/3
train <- train_total[1:120000]
# test data 1/3
test <- train_total[120001:180000]

df <- data.table(train, keep.rownames = F)
# convert dataframe to sparse matrix, which is fit for XGBOOST
sparse_matrix <- sparse.model.matrix(Status~.-1, data = df)
# define output vector, which is the y column
output_vector = df[,Status] == "Show-Up"
# parameters could be redefined after discussio
bst <- xgboost(data =sparse_matrix , label = output_vector, max.depth =7, 
                     eta = 0.2, nthread = 2, nround = 200, objective = "binary:logistic")
# another way to seperate dataset 
#dtrain <- xgb.DMatrix(data = sparse_matrix, label = output_vector)
#bstDMatrix <- xgboost(data = dtrain, max.depth = 2, eta = 1, nthread = 2, nround = 20, objective = "binary:logistic")

# bst <- xgb.train(data=dtrain, booster = "gblinear", max.depth=2, nthread = 2, nround=2,  eval.metric = "error", eval.metric = "logloss", objective = "binary:logistic")

```




```{r}
df2 <- data.table(test, keep.rownames = F)
sparse_matrix2 <- sparse.model.matrix(Status~.-1, data = df2)
predict <- predict(bst, sparse_matrix2)
actual <- df2$Status

actual[which(actual == "Show-Up")] <- "1"
actual[which(actual == "No-Show")] <- "0"

actual <- as.numeric(actual)

LogLossBinary = function(actual, predicted, eps = 1e-15) {
   predicted = pmin(pmax(predicted, eps), 1-eps)
  - (sum(actual * log(predicted) + (1 - actual) * log(1 - predicted))) / length(actual)
}

# logistic loss
LogLossBinary(actual = actual, predicted = predict)

# RUC
library(pROC)
roc_obj <- roc(actual, predict)
auc(roc_obj)

```



```{r}
# build model for prediction
# have not tested result
fake.outcome1 <- c(rep(1,50),rep(1,50))
test$Status <- fake.outcome1
dftest <- data.table(test, keep.rownames = F)
sparse_matrix.test <- sparse.model.matrix(Status~.-1, data = dftest)
pred <- predict(bst, sparse_matrix.test)
#prediction <- as.numeric(pred > 0.5)
upload <- cbind(dftest$ID, pred)


test2$Status <- fake.outcome1
dftest2 <- data.table(test2, keep.rownames = F)
sparse_matrix.test2 <- sparse.model.matrix(Status~.-1, data = dftest2)
pred2 <- predict(bst, sparse_matrix.test2)
#prediction2 <- as.numeric(pred2 > 0.5)
upload2 <- cbind(dftest2$ID, pred2)


write.table(upload, file = "private.csv", sep = ",", col.names=FALSE, row.names = FALSE)
write.table(upload2, file = "public.csv", sep = ",", col.names=FALSE, row.names = FALSE)



```


```{r}
#KNN
library(KODAMA)
library(dplyr)
library(class)
library(gmodels)
train_total$Gender<-as.numeric(train_total$Gender)
train_total$DayOfTheWeek<-as.numeric(factor(train_total$DayOfTheWeek))
train_total$Status<-as.numeric(factor(train_total$Status))
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
train[,1]<-normalize(train[,1])
train[,3]<-normalize(train[,3])
train.x<-as.matrix(train[,1:12])
test[,1]<-normalize(test[,1])
test[,3]<-normalize(test[,3])
test.x<-as.matrix(test[,1:12])
test.response<-test[,13]
response<-as.matrix(train[,13])
pred<-knn(train = train.x,test = test.x,cl=response,k=10)
CrossTable(test.response,pred,prop.chisq = F)
```

